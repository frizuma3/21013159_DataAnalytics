{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frizuma3/21013159_DataAnalytics/blob/main/LinearRegressionTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w9sEQx-NFJv"
      },
      "source": [
        "In this tutorial we will train and test a linear regressor. This is something you have already done in part 3 of the course document. So, I will miss out all of the extra notes and just get to business."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p-7cPGENClE"
      },
      "source": [
        "# needed to create the data frame\n",
        "import pandas as pd\n",
        "\n",
        "# needed to help with speedy maths based calculations\n",
        "import numpy as np\n",
        "\n",
        "# create data frame from csv file we hosted on our github\n",
        "#df = pd.read_csv('https://raw.githubusercontent.com/1122131uhi/dataAnalytics/master/tutorial2lineardata.csv', index_col=0, )\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/frizuma3/21013159_DataAnalytics/refs/heads/main/linearregressiondata.csv', index_col=0, )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEw-Y4JWNkh1",
        "outputId": "b982826a-9fb4-4982-857d-7309f7493b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# make sure we have our data by printing it out\n",
        "print(df[:6])\n",
        "# print(df) #all"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  temp  dewp  NUM_COLLISIONS\n",
            "1    1  83.6  63.0        0.520270\n",
            "2    3  80.3  54.1        0.578829\n",
            "3    4  79.8  56.7        0.804054\n",
            "4    5  81.8  65.6        0.281532\n",
            "5    6  86.7  64.3        0.639640\n",
            "6    7  81.9  62.3        0.745495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTMxwMfGPdWJ"
      },
      "source": [
        "# A scale is not required here, but the constant will be useful in the assignment.\n",
        "SCALE_NUM_TRIPS = 1.0"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "5DzJzm8VY1rG",
        "outputId": "ec08ebee-f9b2-42c1-fe7d-2d680fbb228f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day and NUM_TRIPS"
      ],
      "metadata": {
        "id": "JovHPmArsu9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with the inputs and the output at the end using the imported dataframe. This can be replicated for any configuration, in this case, I have gone for day, temp, wdsp\n",
        "df_input_data_day = [df[\"day\"], df[\"NUM_COLLISIONS\"]]\n",
        "# create headers for our new dataframe. These should correlate with the above.\n",
        "df_input_headers_day = [\"day\", \"NUM_COLLISIONS\"]\n",
        "# create a final dataframe using our new dataframe and headers.\n",
        "df_input_day = pd.concat(df_input_data_day, axis=1, keys=df_input_headers_day)"
      ],
      "metadata": {
        "id": "FWRaDMLVs3mk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a training set for runnign through the model and a test set, we do this by using sample with 0.8 for an 80% training set and 20% for test.\n",
        "training_set_day = df_input_day.sample(frac=0.8, random_state=0)\n",
        "test_set_day = df_input_day.drop(training_set_day.index)"
      ],
      "metadata": {
        "id": "Ty0VniOOvFR0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the datasets and remove the final column, i.e. the output column. We do this using pop.\n",
        "training_features_day = training_set_day.copy()\n",
        "test_features_day = test_set_day.copy()\n",
        "\n",
        "training_labels_day = training_features_day.pop('NUM_COLLISIONS')\n",
        "test_labels_day = test_features_day.pop('NUM_COLLISIONS')"
      ],
      "metadata": {
        "id": "5ojr1YWGvOEj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here I have put in a scale factor and divided by it. In this dataset, I had already normalised and thus it is 1. However, 600000 is what would make sense based on the data here and we can use this later when testing our model..\n",
        "training_labels_day = training_labels_day/SCALE_NUM_TRIPS\n",
        "test_labels_day = test_labels_day/SCALE_NUM_TRIPS"
      ],
      "metadata": {
        "id": "rxC88xHsvYTM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_features_day)"
      ],
      "metadata": {
        "id": "n_OkqLwdx6X4",
        "outputId": "00a0fc6e-7e1a-48aa-ef61-4b6263a0c33d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day\n",
            "2478    2\n",
            "928     5\n",
            "868     2\n",
            "913     4\n",
            "1744    1\n",
            "...   ...\n",
            "1818    6\n",
            "1239    2\n",
            "1902    6\n",
            "500     4\n",
            "1920    3\n",
            "\n",
            "[1884 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boiler plate for this model. You can see that we have used the training_features here for our normalisation layer that we try and fit to the outputs.\n",
        "normaliser_day = tf.keras.layers.Normalization(input_shape=[1,], axis=None) # tf.keras.layers.Normalization(axis=-1)\n",
        "normaliser_day.adapt(np.array(training_features_day))"
      ],
      "metadata": {
        "id": "Qpi6HgPbveSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1640a3af-b9c7-4120-e5b3-bc61781f061d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I have decided to call the model, model_1. We add our normaliser and we are expecting a single output.\n",
        "model_0 = tf.keras.Sequential([\n",
        "    normaliser_day,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "y1-BThwAvhqH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "ddgDNLTfvqOx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are going to fit the model where we require the training features and labels. We will run it 100 times i.e. epochs and we have applied a further 20% validation split.\n",
        "\n",
        "%%time\n",
        "history = model_0.fit(\n",
        "    training_features_day,\n",
        "    training_labels_day,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "CaJk8EUMvt5s",
        "outputId": "1e8fdc09-13b0-4410-b2d3-57b66be62d4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.6 s, sys: 659 ms, total: 14.2 s\n",
            "Wall time: 16.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we will evaluate our model using the test features and labels.\n",
        "mean_absolute_error_model_0 = model_0.evaluate(\n",
        "    test_features_day,\n",
        "    test_labels_day, verbose=0)"
      ],
      "metadata": {
        "id": "g_r2YIo8vzjS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The mean absolute error of the model can be printed out. Remember, we want to minimise this. Perhaps a model with just day and NUM_TRIPS would be better. It will also vary on each training run due to randomisation.\n",
        "print(mean_absolute_error_model_0)"
      ],
      "metadata": {
        "id": "ENe5nS8Qv5vq",
        "outputId": "333ef8d8-07e0-49e2-de7d-ee11f4ebd91d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16121359169483185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we create a custom dataframe with 3 values per feature.\n",
        "input_model_0 = pd.DataFrame.from_dict(data =\n",
        "\t\t\t\t{\n",
        "            'day' : [1,2,3,4,5,6,7],\n",
        "        })"
      ],
      "metadata": {
        "id": "njtCqp0Swcs5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_predictions_model_0 = model_0.predict(input_model_0)*SCALE_NUM_TRIPS # essentially 600000 in this instance would give back realistic numbers based on the TAXI_TRIPS data\n",
        "print(linear_predictions_model_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3WXh6xlwlx3",
        "outputId": "94e6d713-6807-4afb-f863-bcb4f1fd4125"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "[[0.5675329 ]\n",
            " [0.5978414 ]\n",
            " [0.6281498 ]\n",
            " [0.65845823]\n",
            " [0.68876666]\n",
            " [0.7190751 ]\n",
            " [0.74938357]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day, Temp, Windspeed, NUM_TRIPS\n"
      ],
      "metadata": {
        "id": "TS_y_-9uspzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with the inputs and the output at the end using the imported dataframe. This can be replicated for any configuration, in this case, I have gone for day, temp, wdsp\n",
        "df_input_data = [df[\"day\"], df[\"temp\"], df[\"dewp\"], df[\"NUM_COLLISIONS\"]]\n",
        "# create headers for our new dataframe. These should correlate with the above.\n",
        "df_input_headers = [\"day\", \"temp\", \"dewp\", \"NUM_COLLISIONS\"]\n",
        "# create a final dataframe using our new dataframe and headers.\n",
        "df_input = pd.concat(df_input_data, axis=1, keys=df_input_headers)"
      ],
      "metadata": {
        "id": "WHuSnr6LdC3J"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a training set for runnign through the model and a test set, we do this by using sample with 0.8 for an 80% training set and 20% for test.\n",
        "training_set = df_input.sample(frac=0.8, random_state=0)\n",
        "test_set = df_input.drop(training_set.index)"
      ],
      "metadata": {
        "id": "d5JtvdLBcruq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the datasets and remove the final column, i.e. the output column. We do this using pop.\n",
        "training_features = training_set.copy()\n",
        "test_features = test_set.copy()\n",
        "\n",
        "training_labels = training_features.pop('NUM_COLLISIONS')\n",
        "test_labels = test_features.pop('NUM_COLLISIONS')"
      ],
      "metadata": {
        "id": "EILvYoDid0wI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here I have put in a scale factor and divided by it. In this dataset, I had already normalised and thus it is 1. However, 600000 is what would make sense based on the data here and we can use this later when testing our model..\n",
        "training_labels = training_labels/SCALE_NUM_TRIPS\n",
        "test_labels = test_labels/SCALE_NUM_TRIPS"
      ],
      "metadata": {
        "id": "3NBSa-Wyf2r6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boiler plate for this model. You can see that we have used the training_features here for our normalisation layer that we try and fit to the outputs.\n",
        "normaliser = tf.keras.layers.Normalization(axis=-1)\n",
        "normaliser.adapt(np.array(training_features))"
      ],
      "metadata": {
        "id": "VQuNfPpdf9al"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I have decided to call the model, model_1. We add our normaliser and we are expecting a single output.\n",
        "model_1 = tf.keras.Sequential([\n",
        "    normaliser,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "JKiP5GIrgIJH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# more boiler plate for creating a sequential model, we need an optimiser and loss parameter. Here we are going to be using the mean absolute error MAE\n",
        "model_1.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "4odNLaUHgNb7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are going to fit the model where we require the training features and labels. We will run it 100 times i.e. epochs and we have applied a further 20% validation split.\n",
        "\n",
        "%%time\n",
        "history = model_1.fit(\n",
        "    training_features,\n",
        "    training_labels,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "rW1K3GxUgQyC",
        "outputId": "5f7c1430-dec6-4ed6-8d0b-471a94cc1dfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.1 s, sys: 625 ms, total: 13.7 s\n",
            "Wall time: 15.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we will evaluate our model using the test features and labels.\n",
        "mean_absolute_error_model_1 = model_1.evaluate(\n",
        "    test_features,\n",
        "    test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "ALdhLDb_gSjq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The mean absolute error of the model can be printed out. Remember, we want to minimise this. Perhaps a model with just day and NUM_TRIPS would be better. It will also vary on each training run due to randomisation.\n",
        "print(mean_absolute_error_model_1)"
      ],
      "metadata": {
        "id": "NVLVxc_aghcD",
        "outputId": "0663a187-39c1-433e-c727-ed618fa60b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16298288106918335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we create a custom dataframe with 3 values per feature.\n",
        "input_1 = pd.DataFrame.from_dict(data =\n",
        "\t\t\t\t{\n",
        "            'day' : [1,1,1],\n",
        "            'temp' : [83.6 , 80.3, 79.8],\n",
        "            'dewp' : [63.0, 54.1, 56.7]\n",
        "        })"
      ],
      "metadata": {
        "id": "hdG-BTFwhNT1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_1.head()"
      ],
      "metadata": {
        "id": "g91lv_a0uoSh",
        "outputId": "3a5879ab-0a95-4618-f0a0-624beb8e8aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   day  temp  dewp\n",
              "0    1  83.6  63.0\n",
              "1    1  80.3  54.1\n",
              "2    1  79.8  56.7"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f2cd8e1-b94f-4a9f-8c95-3ac2f9da7b07\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>83.6</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>80.3</td>\n",
              "      <td>54.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>79.8</td>\n",
              "      <td>56.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f2cd8e1-b94f-4a9f-8c95-3ac2f9da7b07')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f2cd8e1-b94f-4a9f-8c95-3ac2f9da7b07 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f2cd8e1-b94f-4a9f-8c95-3ac2f9da7b07');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da09e466-3e49-4bf7-afb3-bb34432f07ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da09e466-3e49-4bf7-afb3-bb34432f07ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da09e466-3e49-4bf7-afb3-bb34432f07ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "input_1",
              "summary": "{\n  \"name\": \"input_1\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.064784088793142,\n        \"min\": 79.8,\n        \"max\": 83.6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          83.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dewp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.576388678131844,\n        \"min\": 54.1,\n        \"max\": 63.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          63.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next we can check this out, you can multiply by 600000 to get more realistic NUM_TRIPS values.\n",
        "linear_day_predictions_1 = model_1.predict(input_1[:3])*SCALE_NUM_TRIPS # essentially 600000 in this instance would give back realistic numbers based on the TAXI_TRIPS data\n",
        "print(linear_day_predictions_1)"
      ],
      "metadata": {
        "id": "bk96l6IfjA_1",
        "outputId": "9b4df718-3a2c-4402-fad2-93ebac692594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "[[0.26524293]\n",
            " [0.30014187]\n",
            " [0.28959346]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From test inputs we have used, the first element in the array here is similar to this actual data:\n",
        "\n",
        "\"165\",1,62.4,5.6,0.668458757342322\n",
        "\n",
        "We can see that the temperature is slightly higher in the test data (which means less trips, but slightly higher wind means more trips. So, the difference between (actual) 0.668 and (predicted) 0.576 (rounded to 3 significant figures) seems reasonable.\n",
        "\n",
        "Similarly with the second:\n",
        "\n",
        "\"389\",1,26.6,3.1,0.763954173062719, which has higher number of trips due to a lower temperature and also with a slightly higher wind speed.\n",
        "\n",
        "And with the third:\n",
        "\n",
        "\"571\",1,77.2,8.4,0.724652060408235\n",
        "\n",
        "The last prediction with the higher temperature seems to punish the values more."
      ],
      "metadata": {
        "id": "MZNN3Pdbj1I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same as above\n",
        "input_2 = pd.DataFrame.from_dict(data =\n",
        "\t\t\t\t{\n",
        "            'day' : [6,6,6],\n",
        "            'temp' : [83.6 , 80.3, 79.8],\n",
        "            'dewp' : [63.0, 54.1, 56.7]\n",
        "        })"
      ],
      "metadata": {
        "id": "1JBbhB3_kAZ0"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_day_predictions_2 = model_1.predict(input_2[:3])*SCALE_NUM_TRIPS # essentially 600000 in this instance would give back realistic numbers based on the TAXI_TRIPS data\n",
        "print(linear_day_predictions_2)"
      ],
      "metadata": {
        "id": "7wxV7TMMkJYn",
        "outputId": "5024f27f-c444-4a50-a495-1a66cf79026f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "[[0.49341384]\n",
            " [0.5283128 ]\n",
            " [0.5177644 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test uses day 6 (Friday) instead of day 1 (Sunday) which shows higher number of trips. The other values were left the same."
      ],
      "metadata": {
        "id": "03hutuiGkR8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to think about for the assignment. Make a validation set i.e. 5% of the data (or maybe more). This should be used for this type of testing. My values are simply made up.\n",
        "\n",
        "You should also remember to use different models with different data. In this case, I would maybe take each input valuable separately and make a regression model for each, then different variations i.e. any 2.\n",
        "\n",
        "Remember, you need to write up your results in the assignment."
      ],
      "metadata": {
        "id": "0Mq41NEMkdqb"
      }
    }
  ]
}