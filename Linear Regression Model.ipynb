{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frizuma3/21013159_DataAnalytics/blob/main/Linear%20Regression%20Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w9sEQx-NFJv"
      },
      "source": [
        "LINEAR REGRESSION ANALYSIS\n",
        "\n",
        "In this Assignment2 we will train and test a linear regressor.\n",
        "We will use the data generated from the DAOTW Collision Assignment.\n",
        "\n",
        "This assignment is carried out in Python-Kernel using Google_Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p-7cPGENClE"
      },
      "source": [
        "# needed to create the data frame\n",
        "import pandas as pd\n",
        "\n",
        "# needed to help with speedy maths based calculations\n",
        "import numpy as np\n",
        "\n",
        "# create data frame from csv file we hosted on our github\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/frizuma3/21013159_DataAnalytics/refs/heads/main/linearregressiondata.csv', index_col=0, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEw-Y4JWNkh1",
        "outputId": "268da44c-1af7-4cde-ba2a-791b935b21eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# make sure we have our data by printing it out\n",
        "print(df[:6])\n",
        "# print(df) #all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  temp  dewp  NUM_COLLISIONS\n",
            "1    1  83.6  63.0        0.520270\n",
            "2    3  80.3  54.1        0.578829\n",
            "3    4  79.8  56.7        0.804054\n",
            "4    5  81.8  65.6        0.281532\n",
            "5    6  86.7  64.3        0.639640\n",
            "6    7  81.9  62.3        0.745495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTMxwMfGPdWJ"
      },
      "source": [
        "# A scale is not required here, but the constant will be useful in the assignment.\n",
        "SCALE_NUM_COLLISIONS = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "5DzJzm8VY1rG",
        "outputId": "0a496169-31e2-4101-aedf-f2c28115915c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day and NUM_COLLISIONS"
      ],
      "metadata": {
        "id": "JovHPmArsu9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with the inputs and the output at the end using the imported dataframe. This can be replicated for any configuration, in this case, I have gone for day, temp, dewp\n",
        "df_input_data_day = [df[\"day\"], df[\"NUM_COLLISIONS\"]]\n",
        "# create headers for our new dataframe. These should correlate with the above.\n",
        "df_input_headers_day = [\"day\", \"NUM_COLLISIONS\"]\n",
        "# create a final dataframe using our new dataframe and headers.\n",
        "df_input_day = pd.concat(df_input_data_day, axis=1, keys=df_input_headers_day)"
      ],
      "metadata": {
        "id": "FWRaDMLVs3mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a training set for runnign through the model and a test set, we do this by using sample with 0.8 for an 80% training set and 20% for test.\n",
        "training_set_day = df_input_day.sample(frac=0.8, random_state=0)\n",
        "test_set_day = df_input_day.drop(training_set_day.index)"
      ],
      "metadata": {
        "id": "Ty0VniOOvFR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the datasets and remove the final column, i.e. the output column. We do this using pop.\n",
        "training_features_day = training_set_day.copy()\n",
        "test_features_day = test_set_day.copy()\n",
        "\n",
        "training_labels_day = training_features_day.pop('NUM_COLLISIONS')\n",
        "test_labels_day = test_features_day.pop('NUM_COLLISIONS')"
      ],
      "metadata": {
        "id": "5ojr1YWGvOEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here I have put in a scale factor and divided by it. In this dataset, I had already normalised and thus it is 1. However, 600000 is what would make sense based on the data here and we can use this later when testing our model..\n",
        "training_labels_day = training_labels_day/SCALE_NUM_COLLISIONS\n",
        "test_labels_day = test_labels_day/SCALE_NUM_COLLISIONS"
      ],
      "metadata": {
        "id": "rxC88xHsvYTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_features_day)"
      ],
      "metadata": {
        "id": "n_OkqLwdx6X4",
        "outputId": "07786412-5806-43fe-8ae6-abbfc8b6a5ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      day\n",
            "942     5\n",
            "623     2\n",
            "902     7\n",
            "2050    7\n",
            "575     1\n",
            "...   ...\n",
            "2285    4\n",
            "1191    1\n",
            "340     5\n",
            "47      6\n",
            "754     6\n",
            "\n",
            "[2174 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boiler plate for this model. You can see that we have used the training_features here for our normalisation layer that we try and fit to the outputs.\n",
        "normaliser_day = tf.keras.layers.Normalization(input_shape=[1,], axis=None) # tf.keras.layers.Normalization(axis=-1)\n",
        "normaliser_day.adapt(np.array(training_features_day))"
      ],
      "metadata": {
        "id": "Qpi6HgPbveSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8675147c-8fd3-41f0-867b-303778022dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I have decided to call the model, model_1. We add our normaliser and we are expecting a single output.\n",
        "model_0 = tf.keras.Sequential([\n",
        "    normaliser_day,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "y1-BThwAvhqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "ddgDNLTfvqOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are going to fit the model where we require the training features and labels. We will run it 100 times i.e. epochs and we have applied a further 20% validation split.\n",
        "\n",
        "%%time\n",
        "history = model_0.fit(\n",
        "    training_features_day,\n",
        "    training_labels_day,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "CaJk8EUMvt5s",
        "outputId": "ed031cab-8f57-4ebf-80aa-f61cf537bb9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.2 s, sys: 698 ms, total: 12.9 s\n",
            "Wall time: 14 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we will evaluate our model using the test features and labels.\n",
        "mean_absolute_error_model_0 = model_0.evaluate(\n",
        "    test_features_day,\n",
        "    test_labels_day, verbose=0)"
      ],
      "metadata": {
        "id": "g_r2YIo8vzjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The mean absolute error of the model can be printed out. Remember, we want to minimise this. Perhaps a model with just day and NUM_COLLISIONS would be better. It will also vary on each training run due to randomisation.\n",
        "print(mean_absolute_error_model_0)"
      ],
      "metadata": {
        "id": "ENe5nS8Qv5vq",
        "outputId": "6e0b1227-4316-4b03-9228-b17f05d7c286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1443050056695938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we create a custom dataframe with 3 values per feature.\n",
        "input_model_0 = pd.DataFrame.from_dict(data =\n",
        "\t\t\t\t{\n",
        "            'day' : [1,2,3,4,5,6,7],\n",
        "        })"
      ],
      "metadata": {
        "id": "Euz3V4Rh4GaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_predictions_model_0 = model_0.predict(input_model_0)*SCALE_NUM_COLLISIONS # essentially 10000 in this instance would give back realistic numbers based on the NUM_COLLISIONS data\n",
        "print(linear_predictions_model_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvVUo6mI4MMl",
        "outputId": "4f91b72f-b6b8-44e4-aaa9-75aea2e98a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "[[0.48049745]\n",
            " [0.49589744]\n",
            " [0.5112974 ]\n",
            " [0.5266974 ]\n",
            " [0.5420974 ]\n",
            " [0.5574974 ]\n",
            " [0.5728974 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day, Temp, DewPoint, NUM_COLLISIONS\n"
      ],
      "metadata": {
        "id": "TS_y_-9uspzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with the inputs and the output at the end using the imported dataframe. This can be replicated for any configuration, in this case, I have gone for day, temp, dewp\n",
        "df_input_data = [df[\"day\"], df[\"temp\"], df[\"dewp\"], df[\"NUM_COLLISIONS\"]]\n",
        "# create headers for our new dataframe. These should correlate with the above.\n",
        "df_input_headers = [\"day\", \"temp\", \"dewp\", \"NUM_COLLISIONS\"]\n",
        "# create a final dataframe using our new dataframe and headers.\n",
        "df_input = pd.concat(df_input_data, axis=1, keys=df_input_headers)"
      ],
      "metadata": {
        "id": "WHuSnr6LdC3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a training set for runnign through the model and a test set, we do this by using sample with 0.8 for an 80% training set and 20% for test.\n",
        "training_set = df_input.sample(frac=0.8, random_state=0)\n",
        "test_set = df_input.drop(training_set.index)"
      ],
      "metadata": {
        "id": "d5JtvdLBcruq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the datasets and remove the final column, i.e. the output column. We do this using pop.\n",
        "training_features = training_set.copy()\n",
        "test_features = test_set.copy()\n",
        "\n",
        "training_labels = training_features.pop('NUM_COLLISIONS')\n",
        "test_labels = test_features.pop('NUM_COLLISIONS')"
      ],
      "metadata": {
        "id": "EILvYoDid0wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here I have put in a scale factor and divided by it. In this dataset, I had already normalised and thus it is 1. However, 10000 is what would make sense based on the data here and we can use this later when testing our model..\n",
        "training_labels = training_labels/SCALE_NUM_COLLISIONS\n",
        "test_labels = test_labels/SCALE_NUM_COLLISIONS"
      ],
      "metadata": {
        "id": "3NBSa-Wyf2r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boiler plate for this model. You can see that we have used the training_features here for our normalisation layer that we try and fit to the outputs.\n",
        "normaliser = tf.keras.layers.Normalization(axis=-1)\n",
        "normaliser.adapt(np.array(training_features))"
      ],
      "metadata": {
        "id": "VQuNfPpdf9al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I have decided to call the model, model_1. We add our normaliser and we are expecting a single output.\n",
        "model_1 = tf.keras.Sequential([\n",
        "    normaliser,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "JKiP5GIrgIJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# more boiler plate for creating a sequential model, we need an optimiser and loss parameter. Here we are going to be using the mean absolute error MAE\n",
        "model_1.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "4odNLaUHgNb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are going to fit the model where we require the training features and labels. We will run it 100 times i.e. epochs and we have applied a further 20% validation split.\n",
        "\n",
        "%%time\n",
        "history = model_1.fit(\n",
        "    training_features,\n",
        "    training_labels,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "rW1K3GxUgQyC",
        "outputId": "3cc184e3-6596-4a56-a462-9afb379e8df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.7 s, sys: 733 ms, total: 13.4 s\n",
            "Wall time: 15.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we will evaluate our model using the test features and labels.\n",
        "mean_absolute_error_model_1 = model_1.evaluate(\n",
        "    test_features,\n",
        "    test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "ALdhLDb_gSjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The mean absolute error of the model can be printed out. Remember, we want to minimise this. Perhaps a model with just day and NUM_TRIPS would be better. It will also vary on each training run due to randomisation.\n",
        "print(mean_absolute_error_model_1)"
      ],
      "metadata": {
        "id": "NVLVxc_aghcD",
        "outputId": "bae7337d-9fe4-4c23-e9d7-f74fe26089f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12655597925186157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we create a custom dataframe with 3 values per feature.\n",
        "input_1 = pd.DataFrame.from_dict(data =\n",
        "\t\t\t\t{\n",
        "            'day' : [1,1,1],\n",
        "            'temp' : [83.6, 80.6, 79.7],\n",
        "            'dewp' : [63, 65.5, 68.6]\n",
        "        })"
      ],
      "metadata": {
        "id": "hdG-BTFwhNT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_1.head()"
      ],
      "metadata": {
        "id": "g91lv_a0uoSh",
        "outputId": "12c84363-c824-443a-dc20-51fa17b1e709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   day  temp  dewp\n",
              "0    1  83.6  63.0\n",
              "1    1  80.6  65.5\n",
              "2    1  79.7  68.6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3967b858-9780-4f43-9c98-5923a14cefbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>83.6</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>80.6</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>79.7</td>\n",
              "      <td>68.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3967b858-9780-4f43-9c98-5923a14cefbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3967b858-9780-4f43-9c98-5923a14cefbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3967b858-9780-4f43-9c98-5923a14cefbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-55bba335-f320-4747-b511-896ad7a5a47d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55bba335-f320-4747-b511-896ad7a5a47d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-55bba335-f320-4747-b511-896ad7a5a47d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "input_1",
              "summary": "{\n  \"name\": \"input_1\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.04205778566621,\n        \"min\": 79.7,\n        \"max\": 83.6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          83.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dewp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8053520278211046,\n        \"min\": 63.0,\n        \"max\": 68.6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          63.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next we can check this out, you can multiply by 1000 to get more realistic NUM_COLLISIONS values.\n",
        "linear_day_predictions_1 = model_1.predict(input_1[:3])*SCALE_NUM_COLLISIONS # essentially 1000 in this instance would give back realistic numbers based on the NUMBER OF COLLISIONS data\n",
        "print(linear_day_predictions_1)"
      ],
      "metadata": {
        "id": "bk96l6IfjA_1",
        "outputId": "e3e035c4-f012-45a0-c9d6-a2b7e2708cbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "[[0.46710414]\n",
            " [0.45934793]\n",
            " [0.45915502]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test uses day 1 (Sunday) which shows lower number of collisions."
      ],
      "metadata": {
        "id": "gjzs6aRKLPvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Impact of Temperature and Dew Point:\n",
        "\n",
        "As temperature decreases slightly and dew point increases, the model predicts a slight decrease in collision counts. This pattern suggests that the model has identified a weak positive relationship between temperature and collision counts, where higher temperatures may slightly increase the likelihood of collisions.\n",
        "The small differences in predictions indicate that while temperature and dew point are affecting the predicted collision count, their impact is not very strong, resulting in only minor variations in the output.\n",
        "\n",
        "\n",
        "These predictions imply that within the model, temperature and dew point have an influence on collision counts but a limited one. Since all values for day are constant, the model does not account for the weekly trend here, isolating the effect of weather conditions.\n",
        "The predicted collision counts vary by a small margin (about 150 collisions across the three predictions), which aligns with previous observations that weather conditions (temperature and dew point) tend to have weak correlations with collision frequency.\n",
        "\n",
        "The linear regression model predicts a slight decline in collision counts as temperature decreases and dew point increases. This suggests that, within the model's learned parameters, warmer and drier conditions may correlate with a marginally higher likelihood of collisions, but the effect size is relatively small. The consistent values for day indicate that day-of-week effects are controlled in this test, isolating the weather factors, which exhibit a weak influence on collision counts according to the model. This aligns with earlier correlation analyses showing that while weather factors contribute to collision predictions, they are not dominant predictors.."
      ],
      "metadata": {
        "id": "MZNN3Pdbj1I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same as above\n",
        "input_2 = pd.DataFrame.from_dict(data =\n",
        "\t\t\t\t{\n",
        "            'day' : [7,7,7],\n",
        "            'temp' : [81.9, 78.9, 67.2],\n",
        "            'dewp' : [62.3, 60.7, 62.8]\n",
        "        })"
      ],
      "metadata": {
        "id": "1JBbhB3_kAZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_day_predictions_2 = model_1.predict(input_2[:3])*SCALE_NUM_COLLISIONS # essentially 1000 in this instance would give back realistic numbers based on the NUMBER OF COLLISIONS data\n",
        "print(linear_day_predictions_2)"
      ],
      "metadata": {
        "id": "7wxV7TMMkJYn",
        "outputId": "91458f6b-c92d-4d31-abbb-2f96a35c3a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "[[0.8804865 ]\n",
            " [0.8690072 ]\n",
            " [0.83181125]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test uses day 7 (Friday) instead of day 1 (Sunday) which shows higher number of collisions. The other values were left the same."
      ],
      "metadata": {
        "id": "03hutuiGkR8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Impact of Temperature on Collisions:\n",
        "\n",
        "As temperature decreases from 81.9 to 67.2, the model predicts a decrease in collision counts. This suggests that, on this specific day (Friday), higher temperatures are associated with a higher number of predicted collisions.\n",
        "The drop in predicted collision counts as temperature falls reflects a pattern where warmer days might correlate with increased traffic or activities that lead to more collisions.\n",
        "\n",
        "# Limited Influence of DewPoint:\n",
        "\n",
        "Dew point remains relatively constant across the rows, and the model's predictions do not significantly shift due to dew point variations. This indicates that dew point has a limited impact on the number of collisions, at least for this day in the model’s learned parameters.\n",
        "\n",
        "\n",
        "The model’s predictions indicate a slight but noticeable decrease in collision counts as temperature declines, suggesting that, on Fridays, higher temperatures correlate with a higher risk of collisions (from ~817 to ~757 collisions). Dew point variations have minimal influence. This aligns with the model’s broader pattern associating warmer conditions with increased collision counts, potentially due to greater travel or outdoor activity during warm weather. This trend highlights how specific days (like Fridays) may exhibit unique patterns in collision risk, influenced modestly by weather conditions."
      ],
      "metadata": {
        "id": "0Mq41NEMkdqb"
      }
    }
  ]
}